def plot_and_save_loss(losses, path_png):
    plt.figure()
    plt.plot(np.arange(len(losses)), losses)
    plt.title("Training Loss")
    plt.xlabel("epoch"); plt.ylabel("loss"); plt.tight_layout()
    plt.savefig(path_png, dpi=150); plt.close()

def plot_and_save_importance(W, feat_names, path_png, top_n=20, has_bias=False):
    start = 1 if has_bias else 0
    Wnb = W[start:, :]
    imp = np.linalg.norm(Wnb, axis=1)
    names = feat_names[start:] if feat_names is not None else [f"x{i}" for i in range(W.shape[0])][start:]
    idx = np.argsort(imp)[::-1][:min(top_n, len(imp))]
    plt.figure(figsize=(7, max(4, 0.35*len(idx))))
    y = np.arange(len(idx))
    plt.barh(y, imp[idx]); plt.yticks(y, [names[i] for i in idx]); plt.gca().invert_yaxis()
    plt.title("Top feature importance (‖W‖ across classes)")
    plt.xlabel("L2 norm"); plt.tight_layout()
    plt.savefig(path_png, dpi=150); plt.close()

def plot_and_save_confmat(y_true, y_pred, path_png, k):
    cm = confusion_matrix(y_true, y_pred, labels=list(range(k)))
    plt.figure(figsize=(5,4))
    plt.imshow(cm, interpolation="nearest")
    plt.title("Confusion Matrix"); plt.xlabel("Pred"); plt.ylabel("True")
    plt.colorbar()
    tick_marks = np.arange(k)
    plt.xticks(tick_marks, tick_marks); plt.yticks(tick_marks, tick_marks)
    # annotate
    for i in range(k):
        for j in range(k):
            plt.text(j, i, str(cm[i, j]), ha="center", va="center")
    plt.tight_layout()
    plt.savefig(path_png, dpi=150); plt.close()